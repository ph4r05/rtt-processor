{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rtt_tools import dump_data\n",
    "from rtt_tools.dump_data import *  # pussy died because of this wildcard import\n",
    "from rtt_tools.export import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "coloredlogs.CHROOT_FILES = []\n",
    "coloredlogs.install(level=logging.INFO, use_chroot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtt_tools.gen.max_rounds import FUNC_DB, FuncDb, FuncInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "js1 = json.load(open('/tmp/rtt-results-full9.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "js2 = json.load(open('/tmp/rtt-results-full9-ext01.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = js1 + js2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(js[2829322], indent=2))\n",
    "#for rix, rec in enumerate(js):\n",
    "#    if 'lowmc' in rec['data_type']:\n",
    "#        print(rec['data_type'])\n",
    "#     exp_info = loader.break_exp_ph4(rec['data_type'])\n",
    "#     if not exp_info:\n",
    "#         print('Could not parse %s' % rec['data_type'])\n",
    "#         continue\n",
    "#len(js2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dump_data.Loader()\n",
    "\n",
    "def exp_info_to_rec(exp_info):\n",
    "    return collections.OrderedDict([\n",
    "        ('tp', exp_info.fnc_type),\n",
    "        ('f', exp_info.fnc_name),\n",
    "        ('s', exp_info.size),\n",
    "        ('m', exp_info.meth),\n",
    "        ('r', exp_info.fnc_round),\n",
    "        ('e', exp_info.id),\n",
    "    ])\n",
    "\n",
    "def name_to_dict(name):  # js[0]['data_type']\n",
    "    exp_info = loader.break_exp_ph4(name)\n",
    "    if exp_info is None or exp_info.fnc is None:\n",
    "        exp_info = loader.break_exp_ph4_mpc(name)\n",
    "    if exp_info is None or exp_info.fnc is None:\n",
    "        return None\n",
    "    return exp_info_to_rec(exp_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "funtype = {}  # fun -> type\n",
    "funrounds = collections.defaultdict(lambda: set())  # fun -> set of rounds tested\n",
    "methsize = {}\n",
    "testvariant = {}\n",
    "datatype = {}\n",
    "fnames = set()\n",
    "test_db = collections.defaultdict(lambda: 0)\n",
    "test_db_inv = collections.defaultdict(lambda: 0)\n",
    "test_db_ctr = set()\n",
    "tstart = time.time()\n",
    "\n",
    "# func_name -> (meth, size) -> round -> test:var:subtest -> [pass, fail, fail]  # 3 seed results\n",
    "funcres = collections.defaultdict(                   # fncname\n",
    "    lambda: collections.defaultdict(                 # meth-size\n",
    "        lambda: collections.defaultdict(             # round\n",
    "            lambda: collections.defaultdict(         # test-variant-subtest\n",
    "                lambda: collections.OrderedDict([        \n",
    "                    ('info', None),\n",
    "                    ('recidx', None),\n",
    "                    ('exid', None),\n",
    "                    ('exs', [None]*3),\n",
    "                    ('exs_info', [None]*3),\n",
    "])))))\n",
    "\n",
    "\n",
    "for rix, rec in enumerate(js):\n",
    "    data_type = rec['data_type']\n",
    "    data_type = data_type.replace('stream:cipher', 'stream_cipher')\n",
    "    exp_info = loader.break_exp_ph4(data_type)\n",
    "    if exp_info is None or exp_info.fnc is None:\n",
    "        exp_info = loader.break_exp_ph4_mpc(data_type)\n",
    "    if not exp_info or not exp_info.fnc:\n",
    "        print('Could not parse %s' % data_type)\n",
    "        continue\n",
    "    #if rix > 1000:\n",
    "    #    break\n",
    "        \n",
    "    funtype[exp_info.fnc_name] = exp_info.fnc_type\n",
    "    funrounds[exp_info.fnc_name].add(exp_info.fnc_round)\n",
    "\n",
    "    meth_size = '%s:%s' % (exp_info.meth, exp_info.size)\n",
    "    if 'testmpc' in data_type:\n",
    "        meth_size = '%s:%s:%s' % (exp_info.meth, exp_info.spread, exp_info.size)\n",
    "    if 't:prng-' in data_type:\n",
    "        meth_size = '%s:b%s:%s' % (exp_info.meth, exp_info.fnc_block, exp_info.size)\n",
    "    \n",
    "    methsize[meth_size] = [exp_info.meth, exp_info.size, exp_info.spread]\n",
    "    cround = exp_info.fnc_round  # TODO: not always int\n",
    "    datatype[data_type] = exp_info_to_rec(exp_info)\n",
    "    \n",
    "    test_desc = f'{rec[\"test\"]}##[{rec[\"variant_type\"]}][{rec[\"variant\"]}]##[{rec[\"subtest_type\"]}][{rec[\"subtest\"]}]'\n",
    "    testvariant[test_desc] = collections.OrderedDict([        \n",
    "        ('variant_type', rec[\"variant_type\"]),\n",
    "        ('variant', rec[\"variant\"]),\n",
    "        ('variant_id', rec[\"variant_id\"]),\n",
    "        ('subtest_type', rec[\"subtest_type\"]),\n",
    "        ('subtest', rec[\"subtest\"]),\n",
    "        ('exid', rec[\"exid\"]),\n",
    "    ])\n",
    "    \n",
    "    test_db_ctr.add(test_desc)\n",
    "    fncresrec = funcres[exp_info.fnc_name][meth_size][cround][test_desc]\n",
    "    fncresrec['exid'] = rec['exid']\n",
    "    fncresrec['recidx'] = rix\n",
    "    fncresrec['info'] = data_type\n",
    "    fncresrec['einfo'] = exp_info\n",
    "    \n",
    "    # iterate over subtests\n",
    "    nsubs_passed = 0\n",
    "    for sub in rec['subs']:\n",
    "        is_passed = sub['stats'][0]['pass']\n",
    "        nsubs_passed += int(is_passed)\n",
    "        \n",
    "    nsubs = len(rec['subs'])\n",
    "    npass_ratio = nsubs_passed / nsubs\n",
    "    variant_passed = npass_ratio >= 0.99  # tune this ratio! Ratio of passed subtests to consider test passed\n",
    "    \n",
    "    if exp_info.id >= 3:\n",
    "        print(f'!! Out of range {exp_info.id} for {data_type}')\n",
    "        continue\n",
    "        \n",
    "    fncresrec['exs'][exp_info.id] = variant_passed\n",
    "    fncresrec['exs_info'][exp_info.id] = collections.OrderedDict([\n",
    "        ('exid', rec['exid']),\n",
    "        ('recidx', rix),\n",
    "        ('info', data_type),\n",
    "        ('einfo', exp_info),\n",
    "        ('nsubs', nsubs),\n",
    "        ('nsubsp', nsubs_passed),\n",
    "        ('nsubsr', npass_ratio),\n",
    "    ])\n",
    "    # print('#: %s, pass: %s, pct: %2.7f' % (nsubs, nsubs_passed, 100*nsubs_passed/nsubs))\n",
    "    \n",
    "# Reindex tests so we have stable IDs\n",
    "all_tests = sorted(list(test_db_ctr))\n",
    "for ix, test in enumerate(all_tests):\n",
    "    test_db[test] = ix\n",
    "    test_db_inv[ix] = test\n",
    "    \n",
    "#print(funrounds, funtype, funcres)\n",
    "#print(json.dumps(funcres, indent=2))\n",
    "print('Proc1 done in %s s' % (time.time() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# funcres[\"AES\"][\"ctr:10485760\"][3]\n",
    "# Analyze function -> meth-size -> round; all tests, reject if 2/3 rejected\n",
    "tstart = time.time()\n",
    "\n",
    "# All experiments computed\n",
    "data_type_set = set()\n",
    "\n",
    "# func_name -> (meth, size) -> round -> {summary dict}\n",
    "funcres_agg = collections.defaultdict(               # fncname\n",
    "    lambda: collections.defaultdict(                 # meth-size\n",
    "        lambda: collections.defaultdict(             # round        \n",
    "            lambda: collections.OrderedDict([        \n",
    "                ('num_tests', 0),\n",
    "                ('num_rej', 0),\n",
    "                ('rejects', False),\n",
    "                ('lib_num_tests', 0),\n",
    "                ('lib_num_rej', 0),\n",
    "                ('lib_rejects', False),\n",
    "                ('info', None),\n",
    "                ('einfo', None),\n",
    "                ('exid', None),\n",
    "                ('exs_info', collections.defaultdict(lambda: collections.OrderedDict([\n",
    "                    ('exids', set()),\n",
    "                    ('num_tests', 0),\n",
    "                    ('num_rej', 0),\n",
    "                    ('lib_rejects', 0),\n",
    "                    ('rejs', set()),\n",
    "                    ('all_tests', set()),\n",
    "                ]))),\n",
    "])))) \n",
    "\n",
    "# Liberal thresholding - both of the above\n",
    "liberal_threshold_ratio = 0.011  # at least 0.011 rejection rate\n",
    "liberal_threshold_const = 3  # at least 3 tests\n",
    "conservative_ratio = 0.01  # num_rej / num_tests; num_rej += 1 if the same tests was rejected at least twice; # TUNE THIS!\n",
    "\n",
    "ignore_random_excursions = True\n",
    "ignore_testmpc = False\n",
    "\n",
    "uncomps = 0\n",
    "uncomps_funcs = collections.Counter()\n",
    "uncomps_set = set()\n",
    "uncomps_bat = set()\n",
    "rerun_cmds = collections.defaultdict(lambda: set())\n",
    "nonames_set = set()\n",
    "rerun_tests = collections.defaultdict(lambda: collections.defaultdict(lambda: None))  # ename -> test -> aux data\n",
    "\n",
    "bat_map = {\n",
    "    'NIST Statistical Testing Suite': '--nist_sts',\n",
    "    'Dieharder': '--dieharder',\n",
    "    'TestU01 Alphabit': '--tu01_alphabit',\n",
    "    'TestU01 Small Crush': '--tu01_crush',\n",
    "    'TestU01 Rabbit': '--tu01_rabbit',\n",
    "    'TestU01 Block Alphabit': '--tu01_blockalphabit',\n",
    "    'TestU01 Crush': '--tu01_crush',\n",
    "    'booltest_1': '--booltest-1',\n",
    "    'booltest_2': '--booltest-2',\n",
    "}\n",
    "\n",
    "expfiles = []\n",
    "expfiles_path = '../ph4-01/exps-dump/__expfiles.json'\n",
    "if os.path.exists(expfiles_path):\n",
    "    with open(expfiles_path) as fh:\n",
    "        expfiles = json.load(fh)\n",
    "        \n",
    "        \n",
    "def find_expfile(tpl, expfiles):\n",
    "    for fname in expfiles:\n",
    "        if tpl in fname:\n",
    "            yield fname\n",
    "\n",
    "            \n",
    "for fname in funcres:\n",
    "    for meth_size in funcres[fname]:\n",
    "        for cround in funcres[fname][meth_size]:\n",
    "            ctests = funcres[fname][meth_size][cround]  # all tests map\n",
    "            crec = funcres_agg[fname][meth_size][cround]  # resulting dict\n",
    "            \n",
    "            for ctest in ctests:\n",
    "                data_type_set.add(ctests[ctest][\"info\"])\n",
    "                \n",
    "                for resix, resex in enumerate(ctests[ctest]['exs']):\n",
    "                    if resex is None:\n",
    "                        uncomps += 1\n",
    "                        uncomps_funcs[fname] += 1\n",
    "                        ename = ctests[ctest][\"info\"]\n",
    "                        \n",
    "                        if ignore_random_excursions and 'Random Excursions' in ctest:\n",
    "                            continue\n",
    "                        if ignore_testmpc and 'testmpc' in ename:\n",
    "                            continue\n",
    "                            \n",
    "                        if '-e:' in ename:\n",
    "                            ename2 = re.sub(r'-e:[\\d]-', f'-e:{resix}-', ename)  # get seed run we need\n",
    "                            ename2 = re.sub(r'-i:([\\w]+(:?\\.key)?)-.*', '-i:\\\\1', ename2)  # cut off input specifications\n",
    "                            ename2 = re.sub(r'^PH4-SM-[\\d]+-', '', ename2)  # remove testing prefix, anything goes\n",
    "                            fnames = list(find_expfile('-' + ename2.replace(':', '_'), expfiles))\n",
    "                            if len(fnames) == 0:\n",
    "                                # print(f'! no fnames found. Cfg: {fname} {meth_size} {cround} {ctest} | ename: {ename} | resix: {resix}. (Check expfiles.json)')\n",
    "                                nonames_set.add(ename)\n",
    "                                \n",
    "                            if len(fnames) != 1:\n",
    "                                # print(f'- more fnames than 1 ({len(fnames)}): {fnames}, Cfg: {fname} {meth_size} {cround} {ctest} | ename: {ename} | resix: {resix}')\n",
    "                                fnames.sort(key=natural_sort_key)\n",
    "                                fnames = list(reversed(fnames))\n",
    "                                \n",
    "                            ename = fnames[0] if fnames else ename\n",
    "                            ename = ename.replace('.json', '')\n",
    "                            ename = ename.replace('_', ':')\n",
    "                            ename = ename.replace('stream:cipher', 'stream_cipher')\n",
    "\n",
    "                        elif 'testmpc' in ename:\n",
    "                            ename = re.sub(r'-inp-([\\w]+?)([\\d]+)-', '-inp-\\\\1!XXXX', ename)\n",
    "                            ename = ename.replace('!XXXX', '%02d-' % resix)\n",
    "                            ename = ename.replace('.json', '')\n",
    "                            ename = re.sub(r'^.*-testmpc', 'testmpc', ename)\n",
    "                        \n",
    "                        uncomps_set.add(ename)\n",
    "                        uncomps_bat.add(ctest.split('|')[0])\n",
    "                        rerun_cmds[ename].add(ctest.split('|')[0])\n",
    "                        rerun_tests[ename][ctest] = (cround, ctests[ctest][\"exs\"], ctests[ctest][\"recidx\"], ctests[ctest][\"info\"])\n",
    "                        # print(f'Uncomputed: {fname}-{meth_size}-{cround}-{ctest}-{ctests[ctest][\"exs\"]}-{ctests[ctest][\"recidx\"]}, ename: {ename}, orig: {ctests[ctest][\"info\"]}')\n",
    "                    \n",
    "                if None in ctests[ctest]['exs']:                    \n",
    "                    # print(json.dumps(js[ctests[ctest][\"recidx\"]], indent=2))\n",
    "                    continue\n",
    "                    \n",
    "                # Liberal interpretation: threshold of tests is enough to tell that we reject the generator.\n",
    "                crec['lib_num_tests'] += 1\n",
    "                \n",
    "                # Iterating over seed variant runs for given fname-methsize-round-ctest\n",
    "                exs_info = ctests[ctest]['exs_info']\n",
    "                for ix, exsinfo in enumerate(exs_info):\n",
    "                    if exsinfo is None:\n",
    "                        continue  # test was not found for this exp.id (seed alternation)\n",
    "                        \n",
    "                    # Single test rejects single seed stream\n",
    "                    is_rejected = int(not ctests[ctest]['exs'][ix]) if ctests[ctest]['exs'][ix] is not None else 0 \n",
    "                    ecrec = crec['exs_info'][ix]  # ecrec ~ funcres_agg[fname][meth_size][cround]['exs_info'][ix]\n",
    "                    ecrec['exids'].add(ctests[ctest]['exs_info'][ix]['exid'])\n",
    "                    ecrec['num_tests'] += 1\n",
    "                    ecrec['num_rej'] += is_rejected\n",
    "                    ecrec['all_tests'].add(test_db[ctest])\n",
    "                    if is_rejected:\n",
    "                        ecrec['rejs'].add(test_db[ctest])\n",
    "                        \n",
    "                    # With each update recompute lib_rejects criteria based on the current test results.    \n",
    "                    ecrec['lib_rejects'] = ecrec['num_rej'] >= liberal_threshold_const and (ecrec['num_rej'] / ecrec['num_tests']) >= liberal_threshold_ratio\n",
    "                    \n",
    "                    # Global liberal view, summarizind seed runs\n",
    "                    crec['lib_num_tests'] += 1\n",
    "                    crec['lib_num_rej'] += is_rejected\n",
    "                    \n",
    "                # Conservative interpretation: We reject if we can reproduce the *same test* at least 2 times. \n",
    "                # 'num_rej' is then number of tests that rejected the same input at least 2 times. \n",
    "                is_rejected = sum(ctests[ctest]['exs']) <= 1  # counting passes, 1 or less passes -> rejected (2+ rejections)\n",
    "                crec['num_tests'] += 1  # +1 for each test computed for fnc-methsize-round\n",
    "                crec['num_rej'] += int(is_rejected)  # +1 for each rejection by a single test for fnc-methsize-round, reproduced on 3 buckets\n",
    "                crec['info'] = ctests[ctest]['info']\n",
    "                crec['einfo'] = ctests[ctest]['einfo']\n",
    "                crec['exid'] = ctests[ctest]['exid']\n",
    "\n",
    "            if crec['num_tests'] == 0:\n",
    "                print(f'! zero tests: f:{fname} m:{meth_size} r:{cround}')\n",
    "                continue\n",
    "                \n",
    "            cratio = crec['num_rej'] / crec['num_tests']\n",
    "            crec['rejects'] = cratio >= conservative_ratio\n",
    "            crec['lib_rejects'] = sum([int(crec['exs_info'][kk]['lib_rejects']) for kk in crec['exs_info'].keys()]) > 1 # 2 or more rejects\n",
    "\n",
    "print('Proc2 done in %s s' % (time.time() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* Unrun Experiments:')\n",
    "kspaces = [20, 38, 20, 20, 20, 20, 20]\n",
    "krec = re.compile(r'^\\[(.*?)\\]\\s*\\[(.*?)\\]$')\n",
    "\n",
    "for ename in []:#sorted(list(rerun_tests.keys())):\n",
    "    recs = sorted(list(rerun_tests[ename].keys()))\n",
    "    print(f'\\n{ename}')\n",
    "    for k in recs:\n",
    "        rec = rerun_tests[ename][k]\n",
    "        kcomp = k.split(\"|\", 1)\n",
    "        kcomp = [kcomp[0]] + kcomp[1].split('##')\n",
    "        kcompr = kcomp[:2]\n",
    "        for ixx, cxx in enumerate(kcomp[2:]):\n",
    "            m = krec.match(cxx)\n",
    "            if not m:\n",
    "                kcompr.append(cxx)\n",
    "                continue\n",
    "            kcompr.append(m.group(1))\n",
    "            kcompr.append(m.group(2))\n",
    "            \n",
    "        kform = ' | '.join([x.ljust(kspaces[ix] if ix < len(kspaces) else 20) for ix, x in enumerate(kcompr)])\n",
    "        print(f'  {\"%21s\" % rec[1]} | {kform} | {rec[2]} {rec[3]}')\n",
    "    #raise ValueError()\n",
    "            \n",
    "print('\\n\\n\\n\\n\\n\\n\\n--------------------\\nUncomputed total:', uncomps, 'functions:', uncomps_funcs, ' batteries:', uncomps_bat)\n",
    "for ename in sorted(list(rerun_cmds.keys())):\n",
    "    fname = ename.replace(':', '_')\n",
    "    fname += '.json'\n",
    "    bats = sorted(list(rerun_cmds[ename]))\n",
    "    ename2 = ename.replace('-SM-01-', '-SM-04-')\n",
    "    ename2 = ename2.replace('-SM-02-', '-SM-04-')\n",
    "    fsize = ('100' if '100MiB' in fname else '10') if 'MiB' in fname else ('100' if '100MB' in fname else '10')\n",
    "    print(f\"submit_experiment {' '.join([bat_map[x] for x in bats])} --name '{ename2}' --cfg '/home/debian/rtt-home/RTTWebInterface/media/predefined_configurations/{fsize}MB.json' --cryptostreams-config '{fname}'\")\n",
    "    \n",
    "print('\\n\\n\\n-------------------Resubmit summary:')\n",
    "for ename in sorted(list(rerun_cmds.keys())):\n",
    "    bats = sorted(list(rerun_cmds[ename]))\n",
    "    fsize = ('100' if '100MiB' in fname else '10') if 'MiB' in fname else ('100' if '100MB' in fname else '10')\n",
    "    print(f\"{ename} : {' '.join([bat_map[x] for x in bats])} @ {fsize}MB\")\n",
    "\n",
    "print('\\n\\n\\n-------------------No names sum:')\n",
    "for x in sorted(list(nonames_set)):\n",
    "    print(x)\n",
    "    \n",
    "print('-----------------\\n\\n\\nProc2 done') \n",
    "print('Num of computed experiments: %s' % (len(data_type_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Liberal thresholding\n",
    "# TODO: compute higher rounds for liberal interpretation, e.g., Tangle has not enough\n",
    "use_liberal = True\n",
    "funcs_no_rounds = set(['MCSSHA3', 'Shabal'])\n",
    "\n",
    "log_lines = []\n",
    "table_lines = []\n",
    "tests_to_print = set()\n",
    "\n",
    "exids_recomp_margin = 3  # rounds a top of maximal / the latest fail; only 10 & 100 MB (faster)\n",
    "exids_recompute = collections.defaultdict(  # fname\n",
    "    lambda: collections.defaultdict(        # meth:size\n",
    "        lambda: [[],[]]))                   # set of rounds to compute\n",
    "\n",
    "exids_recomp_margin_1000MB = 1  # rounds a top of maximal / the latest fail\n",
    "exids_recompute_1000MB = collections.defaultdict(  # fname\n",
    "    lambda: collections.defaultdict(        # meth:size\n",
    "        lambda: None))                      # set of rounds to compute\n",
    "\n",
    "exids_computed_1000MB = collections.defaultdict(  # fname\n",
    "    lambda: collections.defaultdict(              # meth:size\n",
    "        lambda: 0))\n",
    "\n",
    "compute_cols = collections.defaultdict(     # ftype:fname\n",
    "    lambda: collections.defaultdict(        # meth:size\n",
    "        lambda: list()))                    # set of rounds to compute\n",
    "\n",
    "computed_cols = collections.defaultdict(     # ftype:fname\n",
    "    lambda: collections.defaultdict(         # meth:size\n",
    "        lambda: set()))                      # set of rounds to compute\n",
    "\n",
    "\n",
    "def natural_sort_key(s, _nsre=re.compile('([0-9]+)')):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in _nsre.split(s)]\n",
    "\n",
    "\n",
    "for fname in sorted(funcres_agg.keys(), key=natural_sort_key):\n",
    "    fname_low = fname.lower()\n",
    "    \n",
    "    # Find info per-fname\n",
    "    fmeth = list(funcres_agg[fname].keys())\n",
    "    fround = list(funcres_agg[fname][fmeth[0]].keys()) if fmeth else None\n",
    "    finfo = funcres_agg[fname][fmeth[0]][fround[0]] if fround else None\n",
    "    finfo = finfo['einfo'] if finfo and 'einfo' in finfo else None\n",
    "        \n",
    "    erec = FUNC_DB.search(fname, FuncInfo.HASH if finfo is not None and finfo.fnc_type == 'hash' else FuncInfo.CIPHER)\n",
    "    if erec is None and finfo.fnc_type == 'prng':\n",
    "        erec = FuncInfo(fname, FuncInfo.PRNG, 0, 1, 1)\n",
    "    \n",
    "    max_rounds_cur = erec.max_rounds if erec else None\n",
    "    crypt_rounds_cur = erec.human_broken_rounds if erec else None\n",
    "    max_rounds_cur_s = ('%3d' % max_rounds_cur) if max_rounds_cur is not None else ' - '\n",
    "    crypt_rounds_cur_s = ('%3d' % crypt_rounds_cur) if crypt_rounds_cur is not None else ' - '\n",
    "    max_rnd_broken = None\n",
    "    max_rnd_broken_100 = None\n",
    "    max_rnd_broken_meth = collections.defaultdict(lambda: 0)\n",
    "    max_rnd_broken_meth_100 = collections.defaultdict(lambda: 0)\n",
    "    min_rnd_meth = collections.defaultdict(lambda: 999)\n",
    "    max_rnd_meth = collections.defaultdict(lambda: 0)\n",
    "    comp_rounds_meth = collections.defaultdict(lambda: list())\n",
    "    ftypename = f'{erec.ftype}:{fname}'\n",
    "    \n",
    "    for meth in sorted(funcres_agg[fname].keys()):\n",
    "        namemeth = funcres_agg[fname][meth]\n",
    "        #if '104857600' not in meth: # or 'sac:' in meth:\n",
    "        #    continue\n",
    "        \n",
    "        h100MB = 104857600\n",
    "        h1000MB = 1048576000\n",
    "        meth_parts = meth.split(':')\n",
    "        meth_size = int(meth_parts[-1])\n",
    "        is_below_1000 = meth_size < h1000MB\n",
    "        is_col_type = '.key' in meth\n",
    "        \n",
    "        rounds = list(namemeth.keys())\n",
    "        for ix, rnd in enumerate(rounds):\n",
    "            if rnd == '1-0-0':\n",
    "                rounds[ix] = 1\n",
    "                namemeth[1] = namemeth['1-0-0']\n",
    "            if rnd == 'x':\n",
    "                namemeth[1] = namemeth['x']\n",
    "                rounds[ix] = 1\n",
    "            if rnd is None:\n",
    "                namemeth[1] = namemeth[None]\n",
    "                rounds[ix] = 1\n",
    "                \n",
    "        rounds.sort()\n",
    "        cexids = [-1]*3\n",
    "        min_rnd_meth[meth] = rounds[0]\n",
    "        max_rnd_meth[meth] = rounds[-1]\n",
    "        comp_rounds_meth[meth] = rounds\n",
    "        for rnd in rounds:\n",
    "            crec = namemeth[rnd]\n",
    "            cexid = crec['exid']\n",
    "            \n",
    "            for ixx in crec['exs_info'].keys():\n",
    "                cexids[ixx] = max(cexids[ixx], max(crec['exs_info'][ixx]['exids']))\n",
    "            \n",
    "            cur_rejects = crec['lib_rejects'] if use_liberal else crec['rejects']\n",
    "            cnum_rej = crec[\"lib_num_rej\"] if use_liberal else crec[\"num_rej\"]\n",
    "            cnum_tests = crec[\"lib_num_tests\"] if use_liberal else crec[\"num_tests\"]\n",
    "            \n",
    "            con_rejects = crec['rejects']\n",
    "            con_num_rej = crec[\"num_rej\"]\n",
    "            con_num_tests = crec[\"num_tests\"]\n",
    "            \n",
    "            # Conservative view on rejection - same test fails at least twice on 3 seed streams\n",
    "            # Liberal: X tests per seed run. Needs to be set properly.\n",
    "            if cur_rejects and (max_rnd_broken is None or rnd > max_rnd_broken):\n",
    "                max_rnd_broken = rnd\n",
    "                \n",
    "            if cur_rejects and is_below_1000 and (max_rnd_broken_100 is None or rnd > max_rnd_broken_100):\n",
    "                max_rnd_broken_100 = rnd\n",
    "                    \n",
    "            if cur_rejects and (max_rnd_broken_meth[meth] is None or rnd > max_rnd_broken_meth[meth]):\n",
    "                max_rnd_broken_meth[meth] = rnd\n",
    "            \n",
    "            if cur_rejects and is_below_1000 and (max_rnd_broken_meth_100[meth] is None or rnd > max_rnd_broken_meth_100[meth]):\n",
    "                max_rnd_broken_meth_100[meth] = rnd\n",
    "            \n",
    "            if is_col_type and is_below_1000:\n",
    "                computed_cols[ftypename][meth].add(rnd)\n",
    "                \n",
    "            # Detailed view on which tests failed in which experiments\n",
    "            # In conservative interpretation, we require the same test to fail at least twice / 3 runs.\n",
    "            # 'num_rej' thus does not have to match rejected tests in particular seed run \n",
    "            # (e.g., if test IDs are disjunct, 'num_rej' is 0)\n",
    "            rejs_details = ''\n",
    "            if cnum_rej < 15:  # disabled for brevity\n",
    "                rejs_details = []\n",
    "                for kix in crec['exs_info'].keys():\n",
    "                    exs_info2 = crec['exs_info'][kix]\n",
    "                    rejs_details.append(sorted(list(exs_info2['rejs'])))\n",
    "                rejs_details = \"[\" + \"; \".join([\", \".join(['%3d' % y for y in x]) for x in rejs_details]) + \"]\"\n",
    "            \n",
    "            conv_str = ''\n",
    "            if use_liberal:\n",
    "                conv_str = '; c %s (%3d/%3d)' % ('R' if con_rejects else '-', con_num_rej, con_num_tests)\n",
    "            \n",
    "            margin_s = ('margin: %.2f %%' % (100.0 * (1 - rnd/max_rounds_cur))) if cur_rejects and max_rounds_cur is not None else '' \n",
    "            vdict = '%s (%3d/%3d%s | %s %s max. %s) %s' % ('R' if cur_rejects else '-', cnum_rej, cnum_tests, conv_str, crypt_rounds_cur_s, max_rounds_cur_s, margin_s, rejs_details)\n",
    "            irnd = rnd\n",
    "            try:\n",
    "                irnd = int(rnd)\n",
    "            except:\n",
    "                pass\n",
    "            srnd = ('%4d' if isinstance(irnd, int) else '%4s') % irnd\n",
    "            \n",
    "            log_lines.append('%25s | %20s | %s | %s' % (fname, meth, srnd, vdict))\n",
    "    \n",
    "        rnd_broken = max_rnd_broken_meth[meth]\n",
    "        rnd_comp = max_rnd_meth[meth]\n",
    "        rnd_comp_min = min_rnd_meth[meth]\n",
    "        \n",
    "        # Compute also x.key for block functions\n",
    "        if erec.ftype == FuncInfo.CIPHER and is_below_1000 and not is_col_type:\n",
    "            meth_broken = max_rnd_broken_meth_100[meth]\n",
    "            orig_range = list(range(meth_broken - 1, meth_broken + 2))\n",
    "            recomp_list = [x for x in orig_range if x > 0 and x <= max_rounds_cur]\n",
    "            \n",
    "            nmeth = f'{meth_parts[0]}.key:{\":\".join(meth_parts[1:])}'\n",
    "            compute_cols[ftypename][nmeth] = recomp_list\n",
    "            \n",
    "            # Another generation methods\n",
    "            #if erec.stype not in (FuncInfo.STREAM, FuncInfo.MPC):\n",
    "            #    nmeth = f'{meth_parts[0]}.key..inp.rnd:{\":\".join(meth_parts[1:])}'\n",
    "            #    compute_cols[ftypename][nmeth] = recomp_list\n",
    "        \n",
    "        # recomp list: start with new rounds only (max computed), upper bound - either max rounds or broken + limit \n",
    "        if fname in funcs_no_rounds:\n",
    "            continue\n",
    "        \n",
    "        # 10, 100 MB comp lists\n",
    "        if True or meth_size < h1000MB:\n",
    "            recomp_list = list(range(max(rnd_comp + 1, rnd_broken + 1), min(max_rounds_cur + 1, max(rnd_comp + 1, rnd_broken + 1 + exids_recomp_margin)))) \n",
    "            if rnd_broken == 0 and rnd_comp > 0:\n",
    "                recomp_list = list(range(rnd_comp_min - 2, rnd_comp_min)) + recomp_list  # 2 rounds down\n",
    "            exids_recompute[ftypename][meth] = [cexids, [x for x in sorted(list(set(recomp_list))) if x > 0 and x <= max_rounds_cur]]\n",
    "\n",
    "        # 1000MB, if detected on the max, add one more; if not detected on minimal, add less more.\n",
    "        if meth_size >= h1000MB:\n",
    "            meth_100 = ':'.join(meth_parts[:-1]) + (':%s' % h100MB)\n",
    "            recomp_list = []\n",
    "            if rnd_broken == 0 and rnd_comp > 0:  # not detected on minimal, add X less\n",
    "                recomp_list += list(range(rnd_comp_min - 2, rnd_comp_min))\n",
    "            if rnd_broken == rnd_comp:  # detected on max, add X more\n",
    "                recomp_list += list(range(rnd_comp + 1, rnd_comp + 3))\n",
    "            \n",
    "            # Add highest detected in 100MB, -1 also for confirmation, +1 for overreach\n",
    "            if meth_100 in max_rnd_broken_meth and meth_100 in max_rnd_meth:\n",
    "                br100 = max_rnd_broken_meth[meth_100]\n",
    "                recomp_list += list(range(br100 - 1, br100 + 2))\n",
    "\n",
    "            # exids_recompute[ftypename][meth] = (cexids, [x for x in sorted(list(set(recomp_list))) if x > 0 and x <= max_rounds_cur])\n",
    "            exids_recompute[ftypename][meth][1] = sorted(list(set(exids_recompute[ftypename][meth][1] + [x for x in sorted(list(set(recomp_list))) if x > 0 and x <= max_rounds_cur])))\n",
    "        \n",
    "        # recomp 1000MB for upper levels, new sizes\n",
    "        if meth_size < h100MB:\n",
    "            continue\n",
    "        \n",
    "        meth_1000 = ':'.join(meth_parts[:-1]) + (':%s' % h1000MB)\n",
    "        recomp_list_1000MB = list(range(max(rnd_broken + 1, rnd_broken + 1), min(max_rounds_cur + 1, max(rnd_broken + 1, rnd_broken + 1 + exids_recomp_margin_1000MB)))) \n",
    "        exids_recompute_1000MB[ftypename][meth_1000] = [cexids, recomp_list_1000MB]\n",
    "        \n",
    "        if meth_size >= h1000MB:\n",
    "            exids_computed_1000MB[ftypename][meth] = max(exids_computed_1000MB[ftypename][meth], rnd_comp)\n",
    "    \n",
    "    # add zero stream, base on ctr estimate\n",
    "    if erec.ftype == FuncInfo.CIPHER and erec.stype == FuncInfo.STREAM:\n",
    "        meth_base_sizes = set([int(x.split(':')[-1]) for x in exids_recompute[ftypename].keys() if '.key' not in x])\n",
    "        for csize in sorted(list(meth_base_sizes)):\n",
    "            ctr_mth = f'ctr:{csize}'\n",
    "            zro_mth = f'zero:{csize}'\n",
    "\n",
    "            if zro_mth not in exids_recompute[ftypename]:\n",
    "                if ctr_mth in comp_rounds_meth:\n",
    "                    b1 = exids_recompute[ftypename][ctr_mth][1] if ctr_mth in exids_recompute[ftypename] else []\n",
    "                    exids_recompute[ftypename][zro_mth] = [[], sorted(list(set(b1 + comp_rounds_meth[ctr_mth])))]\n",
    "                elif ctr_mth in exids_recompute[ftypename]:\n",
    "                    exids_recompute[ftypename][zro_mth] = list(exids_recompute[ftypename][ctr_mth])\n",
    "                else:\n",
    "                    logger.info(f'! Cannot add zero input for {ftypename}')\n",
    "\n",
    "    # .key generator: if rnd.key not present, base on sac estimate\n",
    "    col_meth_sizes = set([int(x.split(':')[-1]) for x in compute_cols[ftypename].keys()])\n",
    "    for csize in sorted(list(col_meth_sizes)):\n",
    "        rnd_mth = f'rnd.key:{csize}'\n",
    "        sac_mth = f'sac.key:{csize}'\n",
    "        ctr_mth = f'ctr.key:{csize}'\n",
    "\n",
    "        if rnd_mth not in compute_cols[ftypename]:\n",
    "            if sac_mth in comp_rounds_meth:\n",
    "                compute_cols[ftypename][rnd_mth] = comp_rounds_meth[sac_mth]\n",
    "            elif sac_mth in compute_cols[ftypename]:\n",
    "                compute_cols[ftypename][rnd_mth] = list(compute_cols[ftypename][sac_mth])\n",
    "            elif ctr_mth in compute_cols[ftypename]:\n",
    "                compute_cols[ftypename][rnd_mth] = list(compute_cols[ftypename][ctr_mth])\n",
    "            else:\n",
    "                logger.info(f'! Cannot add rnd.key for {ftypename}')\n",
    "    \n",
    "    # Adapt exids_recompute_1000MB, remove already computed rounds\n",
    "    for cmeth in exids_computed_1000MB[ftypename].keys():\n",
    "        max_rnd = exids_computed_1000MB[ftypename][cmeth]\n",
    "        if cmeth not in exids_recompute_1000MB[ftypename]:\n",
    "            continue\n",
    "        if exids_recompute_1000MB[ftypename][cmeth] is None:\n",
    "            continue\n",
    "        exids_recompute_1000MB[ftypename][cmeth][1] = [x for x in exids_recompute_1000MB[ftypename][cmeth][1] if x > max_rnd]\n",
    "    \n",
    "    for cmeth in computed_cols[ftypename].keys():\n",
    "        compute_cols[ftypename][cmeth] = [x for x in compute_cols[ftypename][cmeth] if x not in computed_cols[ftypename][cmeth]]\n",
    "    \n",
    "    # comp cleanup\n",
    "    for cmeth in list(exids_computed_1000MB[ftypename].keys()):\n",
    "        if exids_recompute_1000MB[ftypename][cmeth] is None or len(exids_recompute_1000MB[ftypename][cmeth][1]) == 0:\n",
    "            del exids_recompute_1000MB[ftypename][cmeth]\n",
    "    for cmeth in list(exids_recompute[ftypename].keys()):\n",
    "        if exids_recompute[ftypename][cmeth] is None or len(exids_recompute[ftypename][cmeth][1]) == 0:\n",
    "            del exids_recompute[ftypename][cmeth]\n",
    "    \n",
    "    if max_rnd_broken is None and crypt_rounds_cur is None and max_rounds_cur is None:\n",
    "        print('Skipping null %s' % fname)\n",
    "        continue\n",
    "    \n",
    "    nfname = fname\n",
    "    nfname = nfname.replace('ROAD-RUNNER-K80', 'R.RUNNER.K80')\n",
    "    nfname = nfname.replace('ROAD-RUNNER-K128', 'R.RUNNER.K128')\n",
    "    nfname = nfname.replace('RECTANGLE-K80', 'RECT.K80')\n",
    "    nfname = nfname.replace('RECTANGLE-K128', 'RECT.K128')\n",
    "    \n",
    "    nfname = nfname.replace('testu01-uxorshift', 'U01.XorShift')\n",
    "    nfname = nfname.replace('testu01-umrg', 'U01.UMRG')\n",
    "    nfname = nfname.replace('testu01-ulcg', 'U01.ULCG')\n",
    "    nfname = nfname.replace('std_subtract_with_carry', 'Std.SubCarry')\n",
    "    nfname = nfname.replace('std_mersenne_twister', 'Std.MTwister')\n",
    "    nfname = nfname.replace('std_lcg', 'Std.LCG')\n",
    "    \n",
    "    nfname = nfname.replace('mimc_hash-', 'MiMC.')\n",
    "    nfname = nfname.replace('gmimc-', 'GMiMC.')\n",
    "    nfname = nfname.replace('lowmc-s', 'LowMC.S')\n",
    "    nfname = nfname.replace('Vision_', 'Vision.')\n",
    "    nfname = nfname.replace('Starkad_', 'Starkad.')\n",
    "    nfname = nfname.replace('Rescue_', 'Rescue.')\n",
    "    nfname = nfname.replace('Poseidon_S128_BLS12_138', 'Poseidon.BLS12')\n",
    "    nfname = nfname.replace('Poseidon_', 'Poseidon.')\n",
    "    \n",
    "    cline = '%s & \\\\boxSecMarginXX{%s}{%s}{%s}' % (nfname, max_rnd_broken or 0, max_rounds_cur or 1, crypt_rounds_cur or 0)\n",
    "    table_lines.append((cline, erec))\n",
    "    \n",
    "    #if len(table_lines)> 10: break\n",
    "\n",
    "    \n",
    "print(\"\\n\".join(log_lines))\n",
    "\n",
    "cols = 3\n",
    "per_col = math.ceil(len(table_lines)/3.0)\n",
    "sorter = lambda x: (x[1].ftype, x[1].stype, natural_sort_key(x[1].fname))\n",
    "table_lines.sort(key=sorter)\n",
    "ntable_lines = []\n",
    "\n",
    "print(\"\\n\\nTable lines: \", len(table_lines), \", per col:\", per_col)\n",
    "# for k, g in itertools.groupby(table_lines, lambda x: (x[1].ftype)):\n",
    "\n",
    "old_type=None\n",
    "for e in table_lines:\n",
    "    if (e[1].ftype, e[1].stype) != old_type:\n",
    "        old_type = (e[1].ftype, e[1].stype)\n",
    "        if old_type[0] == FuncInfo.HASH:\n",
    "            ntable_lines.append('\\\\multicolumn{3}{|l|}{\\\\textbf{Hash functions}}')\n",
    "        elif old_type[0] == FuncInfo.CIPHER and old_type[1] == 0:\n",
    "            ntable_lines.append('\\\\multicolumn{3}{|l|}{\\\\textbf{Block ciphers}}')\n",
    "        elif old_type[0] == FuncInfo.CIPHER and old_type[1] == 2:\n",
    "            ntable_lines.append('\\\\multicolumn{3}{|l|}{\\\\textbf{Stream ciphers}}')\n",
    "        elif old_type[0] == FuncInfo.CIPHER and old_type[1] == 4:\n",
    "            ntable_lines.append('\\\\multicolumn{3}{|l|}{\\\\textbf{MPC ciphers}}')\n",
    "        elif old_type[0] == FuncInfo.PRNG:\n",
    "            ntable_lines.append('\\\\multicolumn{3}{|l|}{\\\\textbf{PRNGs}}')\n",
    "        \n",
    "    ntable_lines.append(e[0])\n",
    "\n",
    "print(len(ntable_lines))\n",
    "per_col = math.ceil(len(ntable_lines)/3.0)\n",
    "arcols = [ntable_lines[i*per_col: (i+1)*per_col] for i in range(cols)]\n",
    "\n",
    "for x in range(per_col):\n",
    "    tup = arcols[0][x] if x < len(arcols[0]) else '& ', arcols[1][x] if x < len(arcols[1]) else '& ', arcols[2][x] if x < len(arcols[2]) else '& '\n",
    "    print(\"& \".join(tup) + \"\\\\\\\\\")\n",
    "\n",
    "#for x in range(per_col):\n",
    "#    l1 =    \n",
    "#print(\"\\n\".join(ntable_lines))\n",
    "\n",
    "# Specs for adding new rounds to compute\n",
    "print('-----\\n\\n\\n Compute more rounds for 10/100:\\n', json.dumps(exids_recompute))#, indent=2))    \n",
    "print('-----\\n\\n\\n Compute more rounds for 1000:\\n', json.dumps(exids_recompute_1000MB))#, indent=2))         \n",
    "print('-----\\n\\n\\n Compute cols:\\n', json.dumps(compute_cols))#, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
